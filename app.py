"""
H·ªá th·ªëng AI H·ªó tr·ª£ Ph√°t hi·ªán S·ªõm Parkinson
Phi√™n b·∫£n c·∫£i ti·∫øn v·ªõi:
- Ph√¢n t√≠ch t·ªïng h·ª£p (·∫¢nh + Tri·ªáu ch·ª©ng)
- T·ªëi ∆∞u h√≥a prompt v·ªõi c·∫£nh b√°o y t·∫ø
- Kh√¥ng h∆∞·ªõng d·∫´n d√πng thu·ªëc
- Khuy·∫øn kh√≠ch thƒÉm kh√°m b√°c sƒ©
"""

import os
import base64
import io
import torch
import torchvision.transforms as transforms
from torchvision import models
from PIL import Image
import cv2
import numpy as np
from flask import Flask, render_template, request, jsonify
import google.generativeai as genai
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Flask app
app = Flask(__name__)
app.secret_key = os.getenv("SECRET_KEY", "default_secret_key")

# Configure Gemini
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemma-3-12b-it")

if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)
    gemini_model = genai.GenerativeModel(GEMINI_MODEL)
    print(f"‚úÖ Gemini model initialized: {GEMINI_MODEL}")
else:
    gemini_model = None
    print("‚ö†Ô∏è Warning: GOOGLE_API_KEY not found")

# ========================================
# LOAD PYTORCH MODEL
# ========================================
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
MODEL_PATH = os.path.join(os.path.dirname(__file__), "MoHinh", "mo_hinh_AI.pth")

model = None
if os.path.exists(MODEL_PATH):
    try:
        model = models.resnet18()
        model.fc = torch.nn.Linear(model.fc.in_features, 2)
        model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
        model = model.to(DEVICE)
        model.eval()
        print(f"‚úÖ Model loaded from {MODEL_PATH}")
    except Exception as e:
        print(f"‚ùå Error loading model: {e}")
else:
    print(f"‚ùå Model file not found: {MODEL_PATH}")

CLASS_NAMES = ["Healthy (B√¨nh th∆∞·ªùng)", "Parkinson (C√≥ d·∫•u hi·ªáu)"]

# ========================================
# IMAGE PREPROCESSING
# ========================================
def preprocess_spiral_image(image_pil):
    """
    Ti·ªÅn x·ª≠ l√Ω ·∫£nh xo·∫Øn ·ªëc v·ªõi c√°c b∆∞·ªõc:
    1. Grayscale
    2. Noise Reduction (GaussianBlur + Bilateral Filter)
    3. CLAHE
    4. Adaptive Thresholding
    """
    # Convert to OpenCV format
    img_np = np.array(image_pil)
    if len(img_np.shape) == 3:
        if img_np.shape[2] == 4:  # RGBA
            img_np = cv2.cvtColor(img_np, cv2.COLOR_RGBA2BGR)
        else:
            img_np = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)
    
    # 1. Grayscale
    gray = cv2.cvtColor(img_np, cv2.COLOR_BGR2GRAY) if len(img_np.shape) == 3 else img_np
    
    # 2. Noise Reduction
    blur = cv2.GaussianBlur(gray, (5, 5), 0)
    bilateral = cv2.bilateralFilter(blur, 9, 75, 75)
    
    # 3. CLAHE
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    clahe_img = clahe.apply(bilateral)
    
    # 4. Adaptive Threshold
    thresh = cv2.adaptiveThreshold(
        clahe_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY_INV, 11, 2
    )
    
    # Convert back to RGB PIL
    processed = cv2.merge([thresh, thresh, thresh])
    processed_pil = Image.fromarray(processed)
    
    return processed_pil, thresh

# ========================================
# IMAGE PREDICTION
# ========================================
def predict_image_pil(image_pil):
    """Predict t·ª´ PIL Image"""
    if model is None:
        return None, 0.0, None
    
    try:
        # Preprocess
        processed_pil, _ = preprocess_spiral_image(image_pil)
        
        # Transform for model
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
        img_tensor = transform(processed_pil).unsqueeze(0).to(DEVICE)
        
        # Predict
        with torch.no_grad():
            outputs = model(img_tensor)
            probs = torch.softmax(outputs, dim=1)
            confidence, predicted = torch.max(probs, 1)
            
        return CLASS_NAMES[predicted.item()], confidence.item(), processed_pil
        
    except Exception as e:
        print(f"Prediction error: {e}")
        return None, 0.0, None

# ========================================
# SYSTEM PROMPTS - OPTIMIZED
# ========================================
SYSTEM_PROMPT_CHAT = """B·∫°n l√† tr·ª£ l√Ω AI y t·∫ø chuy√™n v·ªÅ b·ªánh Parkinson, ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi nh√≥m h·ªçc sinh v√† gi√°o vi√™n tr∆∞·ªùng THCS Nguy·ªÖn T·∫•t Th√†nh (Vi·ªát Nam).

## NHI·ªÜM V·ª§ CH√çNH:
- Tr·∫£ l·ªùi c√¢u h·ªèi v·ªÅ b·ªánh Parkinson b·∫±ng ti·∫øng Vi·ªát
- Cung c·∫•p th√¥ng tin ch√≠nh x√°c, d·ªÖ hi·ªÉu v·ªÅ Parkinson
- H∆∞·ªõng d·∫´n b√†i t·∫≠p ph·ª•c h·ªìi ch·ª©c nƒÉng cho b·ªánh nh√¢n Parkinson
- T∆∞ v·∫•n ch·∫ø ƒë·ªô sinh ho·∫°t ph√π h·ª£p

## X·ª¨ L√ù C√ÇU H·ªéI KH√îNG LI√äN QUAN:
1. N·∫øu c√¢u h·ªèi HO√ÄN TO√ÄN kh√¥ng li√™n quan ƒë·∫øn s·ª©c kh·ªèe/y t·∫ø:
   - Tr·∫£ l·ªùi l·ªãch s·ª±: "T√¥i l√† tr·ª£ l√Ω chuy√™n v·ªÅ b·ªánh Parkinson. C√¢u h·ªèi n√†y n·∫±m ngo√†i ph·∫°m vi chuy√™n m√¥n c·ªßa t√¥i. B·∫°n c√≥ th·∫Øc m·∫Øc g√¨ v·ªÅ Parkinson kh√¥ng?"

2. N·∫øu c√¢u h·ªèi v·ªÅ B·ªÜNH KH√ÅC (kh√¥ng ph·∫£i Parkinson):
   - Tr·∫£ l·ªùi ng·∫Øn g·ªçn n·∫øu bi·∫øt, sau ƒë√≥ nh·∫Øc: "Tuy nhi√™n, chuy√™n m√¥n c·ªßa t√¥i l√† b·ªánh Parkinson. N·∫øu b·∫°n c√≥ tri·ªáu ch·ª©ng l·∫° ho·∫∑c lo l·∫Øng v·ªÅ s·ª©c kh·ªèe, h√£y theo d√µi c∆° th·ªÉ v√† ƒë·∫øn g·∫∑p b√°c sƒ© ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n ch√≠nh x√°c."

3. N·∫øu c√¢u h·ªèi v·ªÅ b·ªánh c√≥ tri·ªáu ch·ª©ng T∆Ø∆†NG T·ª∞ Parkinson (run tay, run ch√¢n Essential Tremor, ƒëa x∆° c·ª©ng, ƒë·ªôt qu·ªµ...):
   - Gi·∫£i th√≠ch s·ª± kh√°c bi·ªát v·ªõi Parkinson
   - Khuy√™n theo d√µi s·ª©c kh·ªèe v√† thƒÉm kh√°m b√°c sƒ© Th·∫ßn kinh ƒë·ªÉ ph√¢n bi·ªát ch√≠nh x√°c

## QUY T·∫ÆC B·∫ÆT BU·ªòC:
1. KH√îNG BAO GI·ªú h∆∞·ªõng d·∫´n s·ª≠ d·ª•ng thu·ªëc ho·∫∑c ƒë·ªÅ c·∫≠p t√™n thu·ªëc c·ª• th·ªÉ
2. LU√îN nh·∫•n m·∫°nh c·∫ßn thƒÉm kh√°m b√°c sƒ© chuy√™n khoa Th·∫ßn kinh
3. N·∫øu ng∆∞·ªùi d√πng h·ªèi v·ªÅ thu·ªëc, tr·∫£ l·ªùi: "T√¥i kh√¥ng th·ªÉ t∆∞ v·∫•n v·ªÅ thu·ªëc. Vi·ªác d√πng thu·ªëc c·∫ßn b√°c sƒ© chuy√™n khoa ch·ªâ ƒë·ªãnh v√† theo d√µi."
4. V·ªõi tri·ªáu ch·ª©ng nguy hi·ªÉm (ng√£ nhi·ªÅu l·∫ßn, kh√≥ nu·ªët, kh√≥ th·ªü, s·ª•t c√¢n nhanh), khuy·∫øn c√°o ƒë·∫øn b·ªánh vi·ªán NGAY
5. Tr·∫£ l·ªùi ng·∫Øn g·ªçn, c√≥ c·∫•u tr√∫c r√µ r√†ng
6. N·∫øu c√≥ tri·ªáu ch·ª©ng l·∫° b·∫•t th∆∞·ªùng, lu√¥n nh·∫Øc: "H√£y theo d√µi s·ª©c kh·ªèe v√† ƒë·∫øn g·∫∑p b√°c sƒ© n·∫øu tri·ªáu ch·ª©ng k√©o d√†i ho·∫∑c n·∫∑ng h∆°n."

## VIDEO B√ÄI T·∫¨P PH·ª§C H·ªíI C√ì S·∫¥N:
Khi ng∆∞·ªùi d√πng h·ªèi v·ªÅ b√†i t·∫≠p, h√£y g·ª£i √Ω C√ÅC VIDEO SAU (d√πng ƒë√∫ng format ƒë·ªÉ hi·ªÉn th·ªã iframe):

1. **C·∫£i thi·ªán c√¢n b·∫±ng v√† d√°ng ƒëi** - Gi√∫p tƒÉng c∆∞·ªùng thƒÉng b·∫±ng, gi·∫£m nguy c∆° t√© ng√£
   [VIDEO:DS73cE9q79o:B√†i t·∫≠p c·∫£i thi·ªán c√¢n b·∫±ng v√† d√°ng ƒëi]

2. **ƒê·ª©ng l√™n ng·ªìi xu·ªëng t·∫°i gi∆∞·ªùng** - TƒÉng c∆∞·ªùng s·ª©c m·∫°nh c∆° ch√¢n
   [VIDEO:bMcCqi6tllk:B√†i t·∫≠p ƒë·ª©ng l√™n ng·ªìi xu·ªëng]

3. **Xoay tr·ªü t·∫°i gi∆∞·ªùng** - C·∫£i thi·ªán v·∫≠n ƒë·ªông khi n·∫±m, gi√∫p d·ªÖ tr·ªü m√¨nh
   [VIDEO:ND5eAvEREmg:B√†i t·∫≠p xoay tr·ªü t·∫°i gi∆∞·ªùng]

## C√ÅCH G·ª¢I √ù VIDEO:
- Khi ng∆∞·ªùi d√πng h·ªèi v·ªÅ b√†i t·∫≠p, CH·ªà C·∫¶N g·ª£i √Ω 1-2 video ph√π h·ª£p nh·∫•t
- D√πng ƒê√öNG format: [VIDEO:VIDEO_ID:T√™n b√†i t·∫≠p]
- Gi·∫£i th√≠ch ng·∫Øn g·ªçn l·ª£i √≠ch c·ªßa b√†i t·∫≠p
- Nh·∫Øc nh·ªü th·ª±c hi·ªán an to√†n, c√≥ ng∆∞·ªùi gi√°m s√°t

## ƒê·ªäNH D·∫†NG:
- D√πng bullet points khi li·ªát k√™
- In ƒë·∫≠m th√¥ng tin quan tr·ªçng
- K·∫øt th√∫c b·∫±ng l·ªùi khuy√™n thƒÉm kh√°m n·∫øu c·∫ßn

## L∆ØU √ù:
ƒê√¢y l√† c√¥ng c·ª• s√†ng l·ªçc h·ªó tr·ª£, KH√îNG thay th·∫ø ch·∫©n ƒëo√°n y khoa chuy√™n nghi·ªáp."""

SYSTEM_PROMPT_COMBINED = """B·∫°n l√† chuy√™n gia AI ph√¢n t√≠ch d·∫•u hi·ªáu b·ªánh Parkinson, ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi nh√≥m h·ªçc sinh v√† gi√°o vi√™n tr∆∞·ªùng THCS Nguy·ªÖn T·∫•t Th√†nh.

## TH√îNG TIN ƒê·∫¶U V√ÄO:
B·∫°n s·∫Ω nh·∫≠n ƒë∆∞·ª£c:
1. K·∫øt qu·∫£ ph√¢n t√≠ch ·∫£nh xo·∫Øn ·ªëc (n·∫øu c√≥)
2. Danh s√°ch tri·ªáu ch·ª©ng ng∆∞·ªùi d√πng ch·ªçn

## NHI·ªÜM V·ª§:
Ph√¢n t√≠ch T·ªîNG H·ª¢P c√°c th√¥ng tin tr√™n ƒë·ªÉ ƒë√°nh gi√° nguy c∆° Parkinson.

## C·∫§U TR√öC TR·∫¢ L·ªúI:

### üìä ƒê√ÅNH GI√Å T·ªîNG QUAN
[M·ª©c ƒë·ªô nguy c∆°: Th·∫•p/Trung b√¨nh/Cao/R·∫•t cao]
[Gi·∫£i th√≠ch ng·∫Øn g·ªçn l√Ω do d·ª±a tr√™n C·∫¢ ·∫£nh v√† tri·ªáu ch·ª©ng]

### üîç PH√ÇN T√çCH CHI TI·∫æT
**V·ªÅ ·∫£nh xo·∫Øn ·ªëc:** [Nh·∫≠n x√©t v·ªÅ ƒë·ªô ƒë·ªÅu, run tay, ki·ªÉm so√°t n√©t v·∫Ω n·∫øu c√≥ ·∫£nh]
**V·ªÅ tri·ªáu ch·ª©ng:** [Ph√¢n t√≠ch t·ª´ng nh√≥m tri·ªáu ch·ª©ng ƒë√£ ch·ªçn: v·∫≠n ƒë·ªông/phi v·∫≠n ƒë·ªông]

### ‚ö†Ô∏è C√ÅC D·∫§U HI·ªÜU C·∫¶N L∆ØU √ù
[Li·ªát k√™ tri·ªáu ch·ª©ng ƒë√°ng lo ng·∫°i, ƒë·∫∑c bi·ªát n·∫øu c√≥ tri·ªáu ch·ª©ng ƒëi·ªÉn h√¨nh Parkinson]

### üí° KHUY·∫æN NGH·ªä
[L·ªùi khuy√™n c·ª• th·ªÉ d·ª±a tr√™n m·ª©c ƒë·ªô nguy c∆°]
[G·ª£i √Ω b√†i t·∫≠p ph·ª•c h·ªìi n·∫øu ph√π h·ª£p]

### üè• KHI N√ÄO C·∫¶N G·∫∂P B√ÅC Sƒ®
[H∆∞·ªõng d·∫´n c·ª• th·ªÉ - LU√îN khuy·∫øn kh√≠ch thƒÉm kh√°m d√π nguy c∆° th·∫•p hay cao]

## QUY T·∫ÆC B·∫ÆT BU·ªòC:
1. KH√îNG ƒë·ªÅ c·∫≠p thu·ªëc ho·∫∑c t√™n thu·ªëc c·ª• th·ªÉ
2. LU√îN khuy·∫øn kh√≠ch thƒÉm kh√°m b√°c sƒ© chuy√™n khoa Th·∫ßn kinh
3. Nh·∫•n m·∫°nh: "ƒê√¢y l√† k·∫øt qu·∫£ s√†ng l·ªçc h·ªó tr·ª£, KH√îNG thay th·∫ø ch·∫©n ƒëo√°n c·ªßa b√°c sƒ©"
4. V·ªõi nguy c∆° cao/r·∫•t cao, khuy·∫øn c√°o kh√°m B√ÅC Sƒ® NGAY
5. N·∫øu c√≥ tri·ªáu ch·ª©ng nguy hi·ªÉm (ng√£ nhi·ªÅu, kh√≥ nu·ªët, s·ª•t c√¢n nhanh): c·∫£nh b√°o ƒë·∫≠m v√† khuy√™n ƒëi vi·ªán
6. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, r√µ r√†ng, d·ªÖ hi·ªÉu, th√¢n thi·ªán
7. Lu√¥n k·∫øt th√∫c b·∫±ng: "H√£y theo d√µi s·ª©c kh·ªèe v√† ƒë·∫øn c∆° s·ªü y t·∫ø ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n ch√≠nh x√°c nh·∫•t."""
# ========================================
# API ROUTES
# ========================================
@app.route('/')
def index():
    return render_template('index.html')

@app.route('/chat', methods=['POST'])
def chat():
    """Chatbot endpoint"""
    try:
        data = request.get_json()
        user_message = data.get('message', '').strip()
        
        if not user_message:
            return jsonify({"error": "Vui l√≤ng nh·∫≠p c√¢u h·ªèi."}), 400
        
        if not gemini_model:
            return jsonify({"error": "AI ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh."}), 500
        
        # Generate response
        prompt = f"{SYSTEM_PROMPT_CHAT}\n\n---\nC√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: {user_message}\n---\nH√£y tr·∫£ l·ªùi:"
        
        response = gemini_model.generate_content(prompt)
        reply = response.text if response else "Xin l·ªói, t√¥i kh√¥ng th·ªÉ tr·∫£ l·ªùi l√∫c n√†y."
        
        # Format response
        reply = format_response_html(reply)
        
        return jsonify({"response": reply})
        
    except Exception as e:
        print(f"Chat error: {e}")
        return jsonify({"error": f"L·ªói x·ª≠ l√Ω: {str(e)}"}), 500

@app.route('/combined_analysis', methods=['POST'])
def combined_analysis():
    """Ph√¢n t√≠ch t·ªïng h·ª£p: ·∫¢nh + Tri·ªáu ch·ª©ng"""
    try:
        # Get symptoms
        import json
        symptoms_json = request.form.get('symptoms', '[]')
        symptoms = json.loads(symptoms_json)
        
        # Get image
        image_file = request.files.get('image')
        image_result = None
        confidence = 0
        image_base64 = None
        
        if image_file:
            image_pil = Image.open(image_file).convert('RGB')
            image_result, confidence, processed_pil = predict_image_pil(image_pil)
            
            # Convert to base64 for display
            buffered = io.BytesIO()
            processed_pil.save(buffered, format="JPEG")
            image_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
        
        # Build prompt
        analysis_input = ""
        
        if image_result:
            analysis_input += f"""
## K·∫æT QU·∫¢ PH√ÇN T√çCH ·∫¢NH XO·∫ÆN ·ªêC:
- K·∫øt qu·∫£: {image_result}
- ƒê·ªô tin c·∫≠y: {confidence * 100:.1f}%
"""
        else:
            analysis_input += "## KH√îNG C√ì ·∫¢NH XO·∫ÆN ·ªêC\n"
        
        if symptoms:
            analysis_input += f"""
## TRI·ªÜU CH·ª®NG NG∆Ø·ªúI D√ôNG CH·ªåN ({len(symptoms)} tri·ªáu ch·ª©ng):
"""
            for i, symptom in enumerate(symptoms, 1):
                analysis_input += f"{i}. {symptom}\n"
        else:
            analysis_input += "## KH√îNG C√ì TRI·ªÜU CH·ª®NG ƒê∆Ø·ª¢C CH·ªåN\n"
        
        # Generate analysis
        if not gemini_model:
            return jsonify({"error": "AI ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh."}), 500
        
        full_prompt = f"{SYSTEM_PROMPT_COMBINED}\n\n{analysis_input}\n\nH√£y ph√¢n t√≠ch t·ªïng h·ª£p:"
        
        response = gemini_model.generate_content(full_prompt)
        analysis = response.text if response else "Kh√¥ng th·ªÉ ph√¢n t√≠ch l√∫c n√†y."
        analysis = format_response_html(analysis)
        
        result = {
            "analysis": analysis,
            "symptoms_count": len(symptoms)
        }
        
        if image_result:
            result["image_result"] = image_result
            result["confidence"] = confidence
            result["image_base64"] = image_base64
        
        return jsonify(result)
        
    except Exception as e:
        print(f"Combined analysis error: {e}")
        return jsonify({"error": f"L·ªói ph√¢n t√≠ch: {str(e)}"}), 500

# ========================================
# HELPER FUNCTIONS
# ========================================
def format_response_html(text):
    """Format markdown to HTML"""
    import re
    
    # Headers
    text = re.sub(r'^### (.+)$', r'<h4 class="font-bold text-teal-700 mt-3 mb-2">\1</h4>', text, flags=re.MULTILINE)
    text = re.sub(r'^## (.+)$', r'<h3 class="font-bold text-lg text-teal-800 mt-4 mb-2">\1</h3>', text, flags=re.MULTILINE)
    text = re.sub(r'^# (.+)$', r'<h2 class="font-bold text-xl text-teal-900 mt-4 mb-3">\1</h2>', text, flags=re.MULTILINE)
    
    # Bold
    text = re.sub(r'\*\*(.+?)\*\*', r'<strong>\1</strong>', text)
    
    # Italic
    text = re.sub(r'\*(.+?)\*', r'<em>\1</em>', text)
    
    # Lists
    lines = text.split('\n')
    result = []
    in_list = False
    
    for line in lines:
        stripped = line.strip()
        if stripped.startswith('- ') or stripped.startswith('‚Ä¢ '):
            if not in_list:
                result.append('<ul class="list-disc pl-5 my-2 space-y-1">')
                in_list = True
            result.append(f'<li>{stripped[2:]}</li>')
        elif re.match(r'^\d+\. ', stripped):
            if not in_list:
                result.append('<ol class="list-decimal pl-5 my-2 space-y-1">')
                in_list = True
            li_content = re.sub(r'^\d+\. ', '', stripped)
            result.append(f'<li>{li_content}</li>')
        else:
            if in_list:
                result.append('</ul>' if result[-1] != '</ol>' else '</ol>')
                in_list = False
            if stripped:
                result.append(f'<p class="mb-2">{stripped}</p>')
            else:
                result.append('<br>')
    
    if in_list:
        result.append('</ul>')
    
    return '\n'.join(result)

# ========================================
# MAIN
# ========================================
if __name__ == '__main__':
    print("\n" + "="*60)
    print("üß† H·ªÜ TH·ªêNG H·ªñ TR·ª¢ PH√ÅT HI·ªÜN S·ªöM PARKINSON")
    print("="*60)
    print(f"üìä Device: {DEVICE}")
    print(f"ü§ñ AI Model: {GEMINI_MODEL}")
    print(f"üîó URL: http://127.0.0.1:5000")
    print("="*60 + "\n")
    
    app.run(debug=True, host='0.0.0.0', port=5000)
